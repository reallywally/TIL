# RAG Best Practice

## 들어가며

RAG를 공부하다 보면 기본적은 흐름과 구조는 이해가 되었다. 이제는 단순 RAG 구현을 넘어 실제 프로덕션 환경에서 어떻게 구현하는지 알아보자. 그리고 앞으로 설명하는 내용은 모범 사례(Best Practice)인 점을 고려하여 진행중인 프로젝트에 맞게 적용해야 한점을 잊지말자.

## RAG 시스템의 전체 아키텍처

RAG 시스템은 크게 문서를 인덱싱처리는 단계외 사용자 질문을 처리하는 단계로 구성된다.

```plaintext
┌─────────────────────────────────────────────────────────┐
  Phase 1: 문서 인덱싱 (오프라인)                           
  문서 수집 → 전처리 → 청킹 → 임베딩 → 벡터 DB 저장           
└─────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────┐
  Phase 2: 쿼리 처리 (온라인 - 실시간)                      
                                                      
  사용자 쿼리                                         
       ↓                                              
  1. 쿼리 전처리 & 분석                               
       ↓                                              
  2. 쿼리 확장/재작성                                 
       ↓                                              
  3. 하이브리드 검색 (벡터 + 키워드)                 
       ↓                                              
  4. 리랭킹 (Re-ranking)                              
       ↓                                              
  5. 컨텍스트 압축 & 정리                             
       ↓                                              
  6. 프롬프트 구성                                    
       ↓                                              
  7. LLM 응답 생성                                    
       ↓                                              
  8. 후처리 & 검증                                    
       ↓                                              
  9. 응답 반환 (출처 포함)                            
       ↓                                              
  10. 피드백 수집 & 로깅                              
└─────────────────────────────────────────────────────────┘
```

## Part1: 문서 인덱싱 - 견고한 기반 다지기

### 1. 문서 수집

다양한 문서 형식을 지원 하여 많은 문서를 수집할 수 있도록 하자. 최소한 아래 문서 형식을 지원하고 가능하면 외부 API도 수집되면 좋다.

- 구조화된 문서: PDF, DOCX
- 마크업 문서: HTML, Markdown, XML
- 플레인 텍스트: TXT, CSV, JSON

> 💡 **실전 팁!**  
> 데이터 수집시 메타데이터는 나중에 검색 필터링, 출처 표시 등 다양한 부분에서 활용되니 반드시 보존하자.
>
> ```python
> metadata = {
>     'source': 'https://example.com/doc.pdf',
>     'title': '제품 사용 가이드',
>     'author': 'Hong Gildong',
>     'created_at': '2024-10-01',
>     'version': '2.0',
>     'document_type': 'manual'
> }
> ```

### 2. 문저 전처리 - 노이즈 제거

원본 문서는 종종 불필요한 요소를 포함한다. 깔끔한 전처리가 임베딩 품질을 크게 좌우한다.

#### 전처리 체크리스트

1. 인코딩(가능하면 UTF-8로 통일)
2. HTML 태그 제거(웹 문서의 경우)
3. 과도한 공백, 줄바꿈 정리
4. 헤더, 푸터, 광고 영역 등 본문과 상관 없는 영역 제거
5. 표와 이미지 처리  
     아래와 같은 표를 그대로 임베딩하면 검색 성능이 떨어질 수 있기 때문에 평문, 구조화된 텍스트로 변환하는것이 좋다.

     |항목|가격|재고|
     |---|---|---|
     |A|1000|50|

     -> "제품 A의 가격은 1000원이며, 재고는 50개입니다."

### 3. 청킹 - RAG의 핵심

청킹(Chunking)은 RAG의 성능을 결정하는 가장 중요한 단계이다. 너무 작으면 문맥이 부족하고, 너무 크면 관련 없는 내용이 섞여 적절한 청킹 사이즈를 찾는 것이 중요하다.
대표적인 전략은 다음과 같다.

#### 1) 고정 길이 청킹

- 개념: 일정한 토큰 수 또는 문자 수 단위로 문서를 자름
- 장점: 구현이 간단하고 균등함
- 단점: 의미가 중간에서 잘릴 수 있음

```plaintext
예시 원문: 
"RAG는 Retrieval-Augmented Generation의 약자이다. 
검색 기반으로 LLM의 한계를 보완하는 기술이다. LangChain, LangGraph 등으로 구현된다."

청킹 결과:
[RAG는 Retrieval-Augme]
[nted Generation의 약자이다]
[. 검색 기반으로 LLM의 한계를 보완] ...
```

#### 2) 의미 기반 청킹

- 개념: 문장 경계, 문단 구조 또는 의미 전환 시점에서 분리
- 장점: 문맥이 자연스럽고 검색 정확도가 높음
- 단점: LLM 또는 분장 분리기를 사용하야 하여 처리 비용이 추가될 수 있음

```plaintext
예시 원문:
"RAG는 검색 결과를 LLM과 결합해 더 정확한 답변을 만드는 구조다.
이때 벡터 데이터베이스를 이용해 관련 문서를 찾는다."

청킹 결과:
["RAG는 검색 결과를 LLM과 결합해 더 정확한 답변을 만드는 구조다."]
["이때 벡터 데이터베이스를 이용해 관련 문서를 찾는다."]
```

#### 3) 문서 구조 기반 청킹

- 개념: 제목, 리스트 등 단위로 나우어 청킹 생성
- 장점: 의미적 문맥 유지
- 단점: 구조 파싱 로직 필요

```plaintext
예시 원문:
## 1. 개요
RAG는 검색과 생성을 결합한다.

## 2. 구성요소
- Retriever
- Generator

청킹 결과:
[섹션1: "개요 - RAG는 검색과 생성을 결합한다."]
[섹션2: "구성요소 - Retriever, Generator"]
```

#### 4) 청킹 오버랩

- 개념: 일정 부분을 중복 시켜 문백의 연속성 확보
- 장점: 앞뒤 문맥을 함께 고려할 수 있음
- 단점: 저장량 증가

```plaintext
예시 원문:
"RAG는 검색 결과를 LLM과 결합해 더 정확한 답변을 만드는 구조다.
이때 벡터 데이터베이스를 이용해 관련 문서를 찾는다."

청킹 결과:
["RAG는 검색 결과를 LLM과 결합해]
[LLM과 결합해 더 정확한 답변을 만드는 구조다."]
["만드는 구조다. 이때 벡터 데이터베이스를"]
["벡터 데이터베이스를 이용해 관련 문서를 찾는다."]
```

다양한 청킹 방법이 있지만 실무에서 대부분은 1개를 선택하는 방식이 아니라 방법을 조합해서 **하이브리드 청킹**으로 한다.
예를들어 1차로 문서 구조 단위 분리하고 2차로 각 섹션을 의미 단위로 분리, 마지막으로 200~400 토큰씩 오버랩한다.

### 4. 임베딩 생성 및 저장

과거에 작성글 중에 임베딩 관련하여 자세히 작성한 글이 있다. 이 부분만 [요기](임베딩을-알아보자.md) 클릭하여 읽어보자.

### 5. 벡터 DB

벡터화된 데이터를 저장할려면 벡터 DB가 필요하다.
그리고 RDB에서 mysql, postgresql, oracle 등 다양한 DB가 있는것 처럼 벡터 DB에도 다양한 종류가 있다.
DB별 특징은 아래와 같이 정리하였다. 당연히 정답은 없으니 상황에 맞게 골라 쓰자.

|DB|장점|단점|추천 상황|
|---|---|---|---|
|Pinecone|완전 관리형(Managed), 빠른 검색 속도, 인덱싱 최적화|비용 (유료 SaaS)|프로덕션, 대용량, 안정성 중요할 때|
|Weaviate|오픈소스, 다양한 기능(GraphQL API, Hybrid Search), 클라우드/온프렘 모두 지원|운영 복잡도, 설정 난이도|자체 호스팅, 유연한 기능 필요 시|
|ChromaDB|가볍고 설치 간단, 로컬 환경에서 빠른 테스트 가능|확장성 제한, 분산 클러스터 미지원|프로토타입, 소규모 프로젝트|
|Qdrant|오픈소스, Rust 기반으로 빠르고 안정적, 성능 우수|커뮤니티 규모 작음|중소규모 RAG, 온프렘 운영 환경|
|Elasticsearch(ES 8+)|Hybrid 검색(Text + Vector), 대규모 검색 인덱스 경험 풍부, 운영 툴 성숙|벡터 전용 기능은 상대적으로 미약, 설정 복잡|기존 Elasticsearch 인프라 보유 시, 하이브리드 검색 활용 시|

## Part2: 쿼리 처리 - 실시간 검색과 생성

이제 사용자 쿼리를 처리하는 과정에 대해 알아보자.

### Step 1. 쿼리 전처리 & 의도 분석

사용자 쿼리는 종종 애매하거나 불완전 하다. 대표적으로 "그거 알려줘" 라는 질문은 이전 대화 내용에 천차만별이 된다. 혹은 "A 제품 설치 중 오류가 발생했어요" 라는건 질문이라기 보단 상황을 전달한다. 이거를 "A 제품 설치 오류 해결 방법"이라는 질문으로 바꿔야한다.

### Step 2. 쿼리 확장 및 재작성

#### 기법 1. HyDE (Hypothetical Document Embeddings)

짧은 쿼리는 검색 성능이 낮다. HyDE라는 방식을 이용하면 쿼리를 문서 수준으로 확장해서 의미를 풍부하게 만든다. 예를 들어 처음 사용자 쿼리로 "LLM의 미세조정이 뭐야?" 라고 한다면 HyDE방식으로 확장시켜서 "이 문서는 대규모 언어모델(LLM)의 미세조정 과정과 원리를 설명합니다. 미세조정은 사전학습된 모델을 특정 태스크에 맞게 추가 학습시키는 과정으로, 데이터셋, 하이퍼파라미터, 학습 절차 등을 다룹니다." 라는 쿼리로 개선한다. 그래서 보통 쿼리가 짧거나 추상적일때 많이 사용한다.

#### 기법 2. 다중 쿼리 생성

하나의 질문을 다양한 각도로 표현하여 검색 커버리지를 높다. 예를들어 "AI 챗봇 만드는 법" 이라는 쿼리를 ["인공지능 챗봇 개발 방법", "대화형 AI 시스템 구축 가이드", "챗봇 프로그래밍 튜토리얼", "LLM 기반 대화 에이전트 제작"] 이렇게 배열로 다중 쿼리를 만든다.

### Step 3. 하이브리드 검색 - 시맨틱 + 키워드

단순 벡터 검색만 이용하면 좋은 결과를 기대하기 부족하다. 전통적 키워드 검색을 결합하면 정확도를 향상 시킬 수 있다.

### Step 4. 리랭킹 - 검색 정호가도의 게임 체인저

Reanker 관련 내용도 과거에 작성했던 [요 파일](Reranker를-알아보자.md)을 확인해 보자.

### Step 5. 컨텍스트 압축 및 최적화

검색된 모든 문서를 LLM에게 전달할 필요는 없다. 리랭킹의 결과를 보고 가장 연관성이 높은 내용만 골라서 LLM에게 전달하자

#### Step 6. 프롬프트 엔지니어링

